
평가 시스템 및 제출방식
===========================

참가팀들이 github에 각자 자신들이 구현한 AI를 업데이트(push)하면,
평가 시스템이 이를 다운로드(clone 또는 pull)하여 평가하고,
결과를 github의 특정 저장소에 업로드(push) 하는 방식으로 진행한다.

.. note::

   모든 저장소는 비공개(private)로 하고, 경진대회 운영진과 공유한다.


저장소 공유
------------

참가팀마다 AI를 제출하기 위한 비공개(private)저장소를 github에 만들고 
경진대회 운영진과 공유하면, 경진대회 운영진에서 아래 세 가지 저장소를 공유한다.

- NCF2020 (https://github.com/rex8312/NCF2020), 
- 제출예제 (https://github.com/rex8312/nc1_simple), 
- 평가결과 (https://github.com/rex8312/NCF2020_Eval) 

AI 제출방식
-------------

참가자들이 AI를 저장소에 push 해두면 토너먼트 시스템이 주기적으로 pull 한다.

**제출 예**: https://github.com/rex8312/nc1_simple


평가 시스템
------------------

평가 시스템은 주기적으로 실행되어 운영진과 공유하고 있는 저장소에서 최신 AI들을 다운받아 평가를 한다.
AI끼리 조합가능한 모든 게임을 100회 플레이(league, round-robin tournament 방식)하고, 
게임 결과(승패, 리플레이 등)를 NCF2020 결과 저장소에 업데이트 한다.

**NCF2020 결과 저장소**: https://github.com/rex8312/NCF2020_Eval

구체적인 평가 스케쥴은 변경될 수 있지만, 일주일에 한번 이상 평가할 예정이다.
중간평가 결과는 최종 경진대회 결과와 무관하다.
중간평가 결과는 주기적으로 삭제될 수 있다.